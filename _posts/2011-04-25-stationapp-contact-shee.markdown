---
layout: post
title: Building a Better Contact Sheet
date: '2011-04-25 13:31:56 -0400'
categories:
- Mobile
- iPhone
author: farski
---
<p><!-- p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Helvetica} p.p2 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Helvetica; min-height: 14.0px} -->Last week we decided to update the Photoshop file we provide to radio stations to allow them to customize the look of our core station iPhone app. There were two main problems with the version we had been using, the first being simply the organization of the layers. There was no standardized mapping of layers in the file to the individual files we need to use in the final app. The other problem was that our process for breaking the file down into its component parts was extremely time consuming. We were using an AppleScript that had been built in-house which extracted specific layers from the document, one-by-one. Additionally, we were maintaining low-res and high-res versions of the template for retina and standard displays.</p>
<p>The solution we decided to implement isn't perfect, but it dramatically speeds up the processing step on our end, allows for a much more sensible organization of the component graphics within the document, and provides a buffer between what the station designer is doing on their end and what we're doing on our end.</p>
<p>[caption id="attachment_311" align="alignright" width="153" caption="Buttons in the SpriteSheet"]<a rel="attachment wp-att-311" href="http://labs.prx.org/2011/04/25/stationapp-contact-shee/screen-shot-2011-04-25-at-2-23-14-pm/"><img class="size-medium wp-image-311" title="StationApp SpriteSheet Screenshot" src="http://labs.prx.org/wp-content/uploads/2011/04/Screen-shot-2011-04-25-at-2.23.14-PM-153x300.png" alt="Buttons in the SpriteSheet" width="153" height="300" /></a>[/caption]</p>
<p>In order to ensure proper and meaningful organization of the template throughout the workflow, each graphical element we require from the stations is now represented as its own Smart Object. Each button, icon, background, etc is a distinct smart object. This way we can be sure that all changes being made to a graphic are in the appropriate and anticipated place. If our default icon is a single, raster layer but the station has a complex multi-layer vector replacement, there is no issue. Unlike the old version where new layers essentially went unaccounted for unless we were told explicitly that they had been added, now all the changes being made to each graphic are entirely encapsulated in a single object. This also allows us to set the canvas size on a per-graphic basis, so a designer doesn't accidentally build a graphic that is too large for the space it will have in the final iPhone app.</p>
<p>Beyond that, the file is simply organized in a way such that relevant smart objects are in layer groups, so it's easy for the designer to find what she is looking for. Icons are all in one place, backgrounds are in another, and status indicators another. All of the default objects are positioned roughly as they would appear in the final app inside a virtual iPhone, ensuring the designer is building the graphics in the correct context.</p>
<p>By using smart objects, we are also able to rethink the way the file is processed once it's returned to PRX. Rather than run it through a script that is heavily dependent on specific layer names, we are now taking advantage of the dynamic Slice tool that Photoshop offers. You may be familiar with using Slice in Photoshop or Fireworks from when people were building websites with tables. It allows you to define contiguous regions of a file which can automatically be batch output, and additionally each slice can be given a unique name that persists inside the Photoshop file itself. The tool also allows slices to be dynamically linked to specific files in the file, and resizes to fit the contents of the layer. In our case, each smart object is a layer that has been linked to a slice, so if a station designer should choose to replace a default with an image that is larger or smaller, the slice we end up outputting is adjusted automatically.</p>
<p>Unfortunately, the slice tool is a relatively simplistic tool, and is only intended to work on the merged contents of the defined area. This is problematic, for instance, with toolbars, where we allow the designer to change both the background and the buttons. In our template we keep those graphics stacked on top of each other, just as they would appear in the app. The slice tool, though, would not handle that situation properly, and would export a single image rather than the separate parts.</p>
<p>Because we're using smart objects, though, it's trivial to duplicate each smart object somewhere else in the file where they can be arranged to prevent overlap. Duplicates of smart objects all point to the same source, so when the designer makes their changes in the part of the file where the layers are arranged to mimic the iPhone, the exploded view of the graphics we maintain behind the seems immediately reflects the changes.</p>
<p>Once we get the file back, we simply hide the designer-facing layers and bring up the matching layers we need for the batch export. A trip to the Save for Web dialog makes the export process take all of 10 seconds, orders of magnitudes faster than the old AppleScript. Since the names of the files being generated are being pulled from the slice metadata we ensure all of the station's images will end up in the appropriate files we need to produce the iPhone app.</p>
<p>There are two caveats with this process. The first is that even though the the canvas size necessary for the user-facing layers is relatively small (technically just the resolution of a retina display), the actual file ends up being much larger. Because we need an unobstructed view of every single element, even when they are placed as closely together as possible the canvas ends up being about 4000x1500. This ends up being just empty space most of the time, and not really a major issue, but it is not ideal.</p>
<p>[caption id="attachment_312" align="aligncenter" width="300" caption="Because we will need to extract images through cropping, the canvas is much larger than the working area."]<a rel="attachment wp-att-312" href="http://labs.prx.org/2011/04/25/stationapp-contact-shee/screen-shot-2011-04-25-at-2-28-20-pm/"><img class="size-medium wp-image-312 " title="Screen shot 2011-04-25 at 2.28.20 PM" src="http://labs.prx.org/wp-content/uploads/2011/04/Screen-shot-2011-04-25-at-2.28.20-PM-300x175.png" alt="" width="300" height="175" /></a>[/caption]</p>
<p style="text-align: center;">&nbsp;</p>
<p>The other problem is something Photoshop is actually doing to give the user more control. Because smart objects can contain vector graphics, Photoshop allows them to be positioned at a sub-pixel level, even in the raster-based world of the actual Photoshop file. It does this even when the smart object contains only raster items itself. An unfortunate side effect of this is that unpredictable rendering can occur. Sometimes when the canvas height or width of a smart object is an odd number, Photoshop will try to center it inside the parent document, which places it halfway between real pixels. When that happens edge pixels of the smart object's contents are improperly rendered (one edge is truncated a row early, and the edge pixels of the opposite edge are repeated). It's not a hard problem to correct, but some care must be given since the entire document is based on smart objects.</p>
